{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Copyright (c) 2023, University of California, Merced. All rights reserved.\n",
    "\n",
    "This file is part of the MummyNutsBench software package developed by\n",
    "the team members of Prof. Xiaoyi Lu's group (PADSYS Lab) at the University\n",
    "of California, Merced.\n",
    "\n",
    "For detailed copyright and licensing information, please refer to the license\n",
    "file LICENSE in the top level directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=:/home/andrew/miniconda3/envs/ssd/lib/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 14:09:24.320289: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-23 14:09:24.325330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:24.325342: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1996109/2615855305.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 14:09:26.385108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 14:09:28.793479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/andrew/miniconda3/envs/ssd/lib/\n",
      "2022-10-23 14:09:28.793751: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH=:/home/andrew/miniconda3/envs/ssd/lib/\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True)\n",
    "#import sys\n",
    "#print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1653715101939,
     "user": {
      "displayName": "Colin Schmierer",
      "userId": "17427459778015434878"
     },
     "user_tz": 420
    },
    "id": "b2fp7iBQIIAQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH='/home/andrew/miniconda3/envs/ssd/lib/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CUSTOM_MODEL_NAME = 'mNuts_centerNet' \n",
    "PRETRAINED_MODEL_NAME = 'centernet_hg104_512x512_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'nuts_label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'TRAIN_PATH': os.path.join('Tensorflow', 'workspace','images', 'train'),\n",
    "    'TEST_PATH': os.path.join('Tensorflow', 'workspace','images', 'test'),\n",
    "    'VALID_PATH': os.path.join('Tensorflow', 'workspace','images', 'valid'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n",
    "\n",
    "#Create dir\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m3iK6ukdIkMv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   888  100   888    0     0   3609      0 --:--:-- --:--:-- --:--:--  3609\n",
      "100 2352k  100 2352k    0     0  4245k      0 --:--:-- --:--:-- --:--:-- 4245k\n",
      "yes: standard output: Broken pipe\n",
      "Archive:  roboflow.zip\n",
      "replace Tensorflow/workspace/images/README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  extracting: Tensorflow/workspace/images/README.dataset.txt  \n",
      "replace Tensorflow/workspace/images/README.roboflow.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  extracting: Tensorflow/workspace/images/README.roboflow.txt  \n",
      " extracting: Tensorflow/workspace/images/test/Nuts.tfrecord  \n",
      " extracting: Tensorflow/workspace/images/test/Nuts_label_map.pbtxt  \n",
      " extracting: Tensorflow/workspace/images/train/Nuts.tfrecord  \n",
      " extracting: Tensorflow/workspace/images/train/Nuts_label_map.pbtxt  \n",
      " extracting: Tensorflow/workspace/images/valid/Nuts.tfrecord  \n",
      " extracting: Tensorflow/workspace/images/valid/Nuts_label_map.pbtxt  \n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "#Download images from roboflow (change link based on annotation set from roboflow)\n",
    "!yes A | curl -L \"https://app.roboflow.com/ds/5NafuLIviG?key=BjvzjqonRs\" > roboflow.zip; yes y | unzip roboflow.zip -d Tensorflow/workspace/images/; rm roboflow.zip\n",
    "!mv Tensorflow/workspace/images/train/Nuts_label_map.pbtxt Tensorflow/workspace/images/train/nuts_label_map.pbtxt;\n",
    "!mv Tensorflow/workspace/images/train/Nuts.tfrecord Tensorflow/workspace/images/train/nuts.tfrecord;\n",
    "!mv Tensorflow/workspace/images/test/Nuts_label_map.pbtxt Tensorflow/workspace/images/test/nuts_label_map.pbtxt;\n",
    "!mv Tensorflow/workspace/images/test/Nuts.tfrecord Tensorflow/workspace/images/test/nuts.tfrecord;\n",
    "!mv Tensorflow/workspace/images/valid/Nuts_label_map.pbtxt Tensorflow/workspace/images/valid/nuts_label_map.pbtxt;\n",
    "!mv Tensorflow/workspace/images/valid/Nuts.tfrecord Tensorflow/workspace/images/valid/nuts.tfrecord;\n",
    "!cp Tensorflow/workspace/images/train/nuts_label_map.pbtxt Tensorflow/workspace/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydeXpQl9InQT"
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7frhKNnuItpd"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_alhhO5DJdyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: apt-get: command not found\n",
      "Processing /home/andrew/mummy_nut/models/center-net/Tensorflow/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (2.39.0)\n",
      "Requirement already satisfied: pillow in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (9.1.1)\n",
      "Requirement already satisfied: lxml in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (4.9.0)\n",
      "Requirement already satisfied: matplotlib in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (3.5.2)\n",
      "Requirement already satisfied: Cython in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (0.29.30)\n",
      "Requirement already satisfied: contextlib2 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Requirement already satisfied: pycocotools in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (2.0.5)\n",
      "Requirement already satisfied: lvis in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (1.7.3)\n",
      "Requirement already satisfied: pandas in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (1.3.5)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (2.9.2)\n",
      "Requirement already satisfied: tensorflow_io in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (0.26.0)\n",
      "Requirement already satisfied: keras in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: oauth2client in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.2.30)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: gin-config in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.51.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.9.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.1)\n",
      "Requirement already satisfied: sacrebleu in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: tensorflow~=2.9.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: sentencepiece in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: seqeval in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Collecting pyyaml<6.0,>=5.1\n",
      "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
      "Requirement already satisfied: tensorflow-addons in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.28.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
      "Requirement already satisfied: tqdm in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
      "Requirement already satisfied: certifi in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.5.18.1)\n",
      "Requirement already satisfied: python-slugify in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: urllib3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from pandas->object-detection==0.1) (2022.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: setuptools in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (59.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.46.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.5.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.20.6)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (7.0.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: orjson<4.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (3.7.2)\n",
      "Requirement already satisfied: docopt in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from lvis->object-detection==0.1) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from matplotlib->object-detection==0.1) (4.33.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: regex in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: portalocker in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: colorama in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: etils[epath] in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: toml in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: promise in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: importlib-resources in /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1695658 sha256=9bafa5a42a91f6ca8acc832587a014c76583e462202f5f3b38445c9d71d6c962\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-phj8l5gf/wheels/f2/29/19/ba3e3051c063695da92b20e451f437d1484cbd3f54fd715b94\n",
      "Successfully built object-detection\n",
      "Installing collected packages: pyyaml, object-detection\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 16] Device or resource busy: '.nfs00000000c41ef5890000001b'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection (Will need to run twice)\n",
    "!apt-get install protobuf-compiler\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5nfBRpZJmcN"
   },
   "outputs": [],
   "source": [
    "# # Verify Installation\n",
    "# VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# !python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "faXi1Sy3LHNP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-22 17:22:31--  http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.189.176, 2607:f8b0:4005:80c::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.189.176|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1426099846 (1.3G) [application/x-tar]\n",
      "Saving to: ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz’\n",
      "\n",
      "centernet_hg104_512 100%[===================>]   1.33G   147MB/s    in 10s     \n",
      "\n",
      "2022-10-22 17:22:42 (134 MB/s) - ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz’ saved [1426099846/1426099846]\n",
      "\n",
      "centernet_hg104_512x512_coco17_tpu-8/\n",
      "centernet_hg104_512x512_coco17_tpu-8/checkpoint/\n",
      "centernet_hg104_512x512_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "centernet_hg104_512x512_coco17_tpu-8/checkpoint/checkpoint\n",
      "centernet_hg104_512x512_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "centernet_hg104_512x512_coco17_tpu-8/pipeline.config\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/saved_model.pb\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/assets/\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/variables/\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "centernet_hg104_512x512_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!wget {PRETRAINED_MODEL_URL}\n",
    "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1995364/4723994.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 14:02:37.368793: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 14:02:37.420589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: '/home/andrew/miniconda3/envs/ssd/lib/'\n",
      "2022-10-23 14:02:37.420838: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4276,
     "status": "ok",
     "timestamp": 1653715482841,
     "user": {
      "displayName": "Colin Schmierer",
      "userId": "17427459778015434878"
     },
     "user_tz": 420
    },
    "id": "s6o2u2Y9LN-v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = os.environ.get(\"LD_LIBRARY_PATH\",\"\")+\":\"+os.environ.get(\"CONDA_PREFIX\")+\"/lib\"\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] += ':/opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4/targets/x86_64-linux/lib/:/opt/nvidia/hpc_sdk/Linux_x86_64/21.9/math_libs/11.4/targets/x86_64-linux/lib/:/home/andrew/centernet/cudnn-linux-x86_64-8.4.0.27_cuda11.6-archive/lib'\n",
    "#os.environ[\"CUDA_DIR\"] = '/opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4'\n",
    "#os.environ[\"XLA_FLAGS\"] = '--xla_gpu_cuda_data_dir=/opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4'\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1653715483816,
     "user": {
      "displayName": "Colin Schmierer",
      "userId": "17427459778015434878"
     },
     "user_tz": 420
    },
    "id": "aDf-fj7IOFOg"
   },
   "outputs": [],
   "source": [
    "#Setup pipeline.config\n",
    "setBatchSize = '1'\n",
    "pipeline = ''\n",
    "with open(os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config')) as file:\n",
    "  pipeline = file.read()\n",
    "  pipeline = pipeline.replace(\"PATH_TO_BE_CONFIGURED\", 'Tensorflow/workspace/pre-trained-models/centernet_hg104_512x512_coco17_tpu-8/checkpoint/ckpt-0', 1)\n",
    "  pipeline = pipeline.replace('PATH_TO_BE_CONFIGURED', 'Tensorflow/workspace/images/train/nuts_label_map.pbtxt', 1)\n",
    "  pipeline = pipeline.replace('PATH_TO_BE_CONFIGURED', 'Tensorflow/workspace/images/train/nuts.tfrecord', 1)\n",
    "  pipeline = pipeline.replace('PATH_TO_BE_CONFIGURED', 'Tensorflow/workspace/images/valid/nuts_label_map.pbtxt', 1)\n",
    "  pipeline = pipeline.replace('PATH_TO_BE_CONFIGURED', 'Tensorflow/workspace/images/valid/nuts.tfrecord', 1)\n",
    "  pipeline = pipeline.replace('batch_size: 128', 'batch_size: ' + setBatchSize, 1)\n",
    "  pipeline = pipeline.replace(\"num_classes: 90\", \"num_classes: 1\", 1)\n",
    "\n",
    "with open(os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config'), 'w') as file:\n",
    "  file.write(pipeline)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5l7li2axOLCJ"
   },
   "outputs": [],
   "source": [
    "#fix import error\n",
    "!yes y | pip uninstall opencv-python-headless\n",
    "!yes y | pip install opencv-python-headless==4.1.2.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'Tensorflow/workspace/models/mNuts_centerNet/ckpt*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm Tensorflow/workspace/models/mNuts_centerNet/ckpt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J3T4QMsTONQq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/mNuts_centerNet --pipeline_config_path=Tensorflow/workspace/models/mNuts_centerNet/pipeline.config --num_train_steps=3000\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=3000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sa6smoRaOVQQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 17:23:59.091532: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-22 17:24:05.057778: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 17:24:05.637063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:17:00.0, compute capability: 8.0\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1022 17:24:05.928079 22407418586624 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 3000\n",
      "I1022 17:24:05.931311 22407418586624 config_util.py:552] Maybe overwriting train_steps: 3000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 17:24:05.931425 22407418586624 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1022 17:24:06.448812 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/images/train/nuts.tfrecord']\n",
      "I1022 17:24:06.453094 22407418586624 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/images/train/nuts.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/images/train/nuts.tfrecord']\n",
      "I1022 17:24:06.453231 22407418586624 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/images/train/nuts.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 17:24:06.453282 22407418586624 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 17:24:06.453325 22407418586624 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 17:24:06.455593 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 17:24:06.476974 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 17:24:12.846115 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1022 17:24:15.657276 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 17:24:18.287572 22407418586624 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-10-22 17:24:36.026690: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-10-22 17:24:36.983717: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 17:24:36.984146: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 17:24:36.984163: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-10-22 17:24:36.984400: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-22 17:24:36.984450: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "ERROR:tensorflow:Couldn't match files for checkpoint Tensorflow/workspace/models/mNuts_centerNet/ckpt-4\n",
      "E1022 17:24:38.372721 22407418586624 checkpoint_management.py:360] Couldn't match files for checkpoint Tensorflow/workspace/models/mNuts_centerNet/ckpt-4\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.129412 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.130598 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.132372 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.133053 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.134721 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.135361 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.137001 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.137660 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.139080 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 17:24:39.139717 22407418586624 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1022 17:24:40.888848 22349436884736 deprecation.py:560] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2022-10-22 17:26:32.215441: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "INFO:tensorflow:Step 100 per-step time 1.220s\n",
      "I1022 17:26:42.567245 22407418586624 model_lib_v2.py:707] Step 100 per-step time 1.220s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.5745848,\n",
      " 'Loss/box/scale': 0.2641814,\n",
      " 'Loss/object_center': 1.3965836,\n",
      " 'Loss/total_loss': 2.2353497,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:26:42.567819 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.5745848,\n",
      " 'Loss/box/scale': 0.2641814,\n",
      " 'Loss/object_center': 1.3965836,\n",
      " 'Loss/total_loss': 2.2353497,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 200 per-step time 0.102s\n",
      "I1022 17:26:52.800832 22407418586624 model_lib_v2.py:707] Step 200 per-step time 0.102s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.67662716,\n",
      " 'Loss/box/scale': 0.26890904,\n",
      " 'Loss/object_center': 0.37999743,\n",
      " 'Loss/total_loss': 1.3255336,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:26:52.801327 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.67662716,\n",
      " 'Loss/box/scale': 0.26890904,\n",
      " 'Loss/object_center': 0.37999743,\n",
      " 'Loss/total_loss': 1.3255336,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 300 per-step time 0.099s\n",
      "I1022 17:27:02.672413 22407418586624 model_lib_v2.py:707] Step 300 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.7132238,\n",
      " 'Loss/box/scale': 0.21689156,\n",
      " 'Loss/object_center': 0.629772,\n",
      " 'Loss/total_loss': 1.5598874,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:02.672887 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.7132238,\n",
      " 'Loss/box/scale': 0.21689156,\n",
      " 'Loss/object_center': 0.629772,\n",
      " 'Loss/total_loss': 1.5598874,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 400 per-step time 0.100s\n",
      "I1022 17:27:12.661618 22407418586624 model_lib_v2.py:707] Step 400 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.36572707,\n",
      " 'Loss/box/scale': 0.44712302,\n",
      " 'Loss/object_center': 0.4073195,\n",
      " 'Loss/total_loss': 1.2201695,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:12.661844 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.36572707,\n",
      " 'Loss/box/scale': 0.44712302,\n",
      " 'Loss/object_center': 0.4073195,\n",
      " 'Loss/total_loss': 1.2201695,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 500 per-step time 0.098s\n",
      "I1022 17:27:22.440101 22407418586624 model_lib_v2.py:707] Step 500 per-step time 0.098s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.17590994,\n",
      " 'Loss/box/scale': 0.28954536,\n",
      " 'Loss/object_center': 0.89669603,\n",
      " 'Loss/total_loss': 1.3621514,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:22.440362 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.17590994,\n",
      " 'Loss/box/scale': 0.28954536,\n",
      " 'Loss/object_center': 0.89669603,\n",
      " 'Loss/total_loss': 1.3621514,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 600 per-step time 0.099s\n",
      "I1022 17:27:32.338464 22407418586624 model_lib_v2.py:707] Step 600 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.46044594,\n",
      " 'Loss/box/scale': 1.0507278,\n",
      " 'Loss/object_center': 1.7606701,\n",
      " 'Loss/total_loss': 3.271844,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:32.338963 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.46044594,\n",
      " 'Loss/box/scale': 1.0507278,\n",
      " 'Loss/object_center': 1.7606701,\n",
      " 'Loss/total_loss': 3.271844,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 700 per-step time 0.100s\n",
      "I1022 17:27:42.295920 22407418586624 model_lib_v2.py:707] Step 700 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.29406494,\n",
      " 'Loss/box/scale': 0.2582322,\n",
      " 'Loss/object_center': 0.4216535,\n",
      " 'Loss/total_loss': 0.9739507,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:42.296149 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.29406494,\n",
      " 'Loss/box/scale': 0.2582322,\n",
      " 'Loss/object_center': 0.4216535,\n",
      " 'Loss/total_loss': 0.9739507,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 800 per-step time 0.099s\n",
      "I1022 17:27:52.212727 22407418586624 model_lib_v2.py:707] Step 800 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.43484464,\n",
      " 'Loss/box/scale': 0.32104787,\n",
      " 'Loss/object_center': 0.48750252,\n",
      " 'Loss/total_loss': 1.243395,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:27:52.213201 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.43484464,\n",
      " 'Loss/box/scale': 0.32104787,\n",
      " 'Loss/object_center': 0.48750252,\n",
      " 'Loss/total_loss': 1.243395,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 900 per-step time 0.098s\n",
      "I1022 17:28:01.993330 22407418586624 model_lib_v2.py:707] Step 900 per-step time 0.098s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.4020603,\n",
      " 'Loss/box/scale': 0.44510326,\n",
      " 'Loss/object_center': 0.20412149,\n",
      " 'Loss/total_loss': 1.051285,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:01.993572 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.4020603,\n",
      " 'Loss/box/scale': 0.44510326,\n",
      " 'Loss/object_center': 0.20412149,\n",
      " 'Loss/total_loss': 1.051285,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.098s\n",
      "I1022 17:28:11.774359 22407418586624 model_lib_v2.py:707] Step 1000 per-step time 0.098s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.40228283,\n",
      " 'Loss/box/scale': 0.36026183,\n",
      " 'Loss/object_center': 0.5249232,\n",
      " 'Loss/total_loss': 1.2874678,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:11.774604 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.40228283,\n",
      " 'Loss/box/scale': 0.36026183,\n",
      " 'Loss/object_center': 0.5249232,\n",
      " 'Loss/total_loss': 1.2874678,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.145s\n",
      "I1022 17:28:26.258201 22407418586624 model_lib_v2.py:707] Step 1100 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.48254696,\n",
      " 'Loss/box/scale': 0.1548854,\n",
      " 'Loss/object_center': 0.9500633,\n",
      " 'Loss/total_loss': 1.5874956,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:26.258454 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.48254696,\n",
      " 'Loss/box/scale': 0.1548854,\n",
      " 'Loss/object_center': 0.9500633,\n",
      " 'Loss/total_loss': 1.5874956,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.099s\n",
      "I1022 17:28:36.163852 22407418586624 model_lib_v2.py:707] Step 1200 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.61377007,\n",
      " 'Loss/box/scale': 0.17394857,\n",
      " 'Loss/object_center': 0.26819214,\n",
      " 'Loss/total_loss': 1.0559108,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:36.164096 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.61377007,\n",
      " 'Loss/box/scale': 0.17394857,\n",
      " 'Loss/object_center': 0.26819214,\n",
      " 'Loss/total_loss': 1.0559108,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.097s\n",
      "I1022 17:28:45.889497 22407418586624 model_lib_v2.py:707] Step 1300 per-step time 0.097s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.9550897,\n",
      " 'Loss/box/scale': 0.21088468,\n",
      " 'Loss/object_center': 0.0566561,\n",
      " 'Loss/total_loss': 1.2226305,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:45.889744 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.9550897,\n",
      " 'Loss/box/scale': 0.21088468,\n",
      " 'Loss/object_center': 0.0566561,\n",
      " 'Loss/total_loss': 1.2226305,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.100s\n",
      "I1022 17:28:55.870189 22407418586624 model_lib_v2.py:707] Step 1400 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.7431359,\n",
      " 'Loss/box/scale': 0.12617794,\n",
      " 'Loss/object_center': 0.49005416,\n",
      " 'Loss/total_loss': 1.3593681,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:28:55.870683 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.7431359,\n",
      " 'Loss/box/scale': 0.12617794,\n",
      " 'Loss/object_center': 0.49005416,\n",
      " 'Loss/total_loss': 1.3593681,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.099s\n",
      "I1022 17:29:05.757594 22407418586624 model_lib_v2.py:707] Step 1500 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.30415514,\n",
      " 'Loss/box/scale': 0.33583245,\n",
      " 'Loss/object_center': 0.5818532,\n",
      " 'Loss/total_loss': 1.2218407,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:05.757831 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.30415514,\n",
      " 'Loss/box/scale': 0.33583245,\n",
      " 'Loss/object_center': 0.5818532,\n",
      " 'Loss/total_loss': 1.2218407,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.100s\n",
      "I1022 17:29:15.730762 22407418586624 model_lib_v2.py:707] Step 1600 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.2871904,\n",
      " 'Loss/box/scale': 0.09770882,\n",
      " 'Loss/object_center': 0.32019818,\n",
      " 'Loss/total_loss': 0.70509744,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:15.730988 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.2871904,\n",
      " 'Loss/box/scale': 0.09770882,\n",
      " 'Loss/object_center': 0.32019818,\n",
      " 'Loss/total_loss': 0.70509744,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.099s\n",
      "I1022 17:29:25.589780 22407418586624 model_lib_v2.py:707] Step 1700 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.49599472,\n",
      " 'Loss/box/scale': 0.23069187,\n",
      " 'Loss/object_center': 0.31651255,\n",
      " 'Loss/total_loss': 1.0431992,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:25.590010 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.49599472,\n",
      " 'Loss/box/scale': 0.23069187,\n",
      " 'Loss/object_center': 0.31651255,\n",
      " 'Loss/total_loss': 1.0431992,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.098s\n",
      "I1022 17:29:35.340461 22407418586624 model_lib_v2.py:707] Step 1800 per-step time 0.098s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.8528762,\n",
      " 'Loss/box/scale': 0.40238476,\n",
      " 'Loss/object_center': 0.5412766,\n",
      " 'Loss/total_loss': 1.7965375,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:35.340690 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.8528762,\n",
      " 'Loss/box/scale': 0.40238476,\n",
      " 'Loss/object_center': 0.5412766,\n",
      " 'Loss/total_loss': 1.7965375,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.098s\n",
      "I1022 17:29:45.090550 22407418586624 model_lib_v2.py:707] Step 1900 per-step time 0.098s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.6019325,\n",
      " 'Loss/box/scale': 0.08778756,\n",
      " 'Loss/object_center': 0.6302791,\n",
      " 'Loss/total_loss': 1.3199992,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:45.090775 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.6019325,\n",
      " 'Loss/box/scale': 0.08778756,\n",
      " 'Loss/object_center': 0.6302791,\n",
      " 'Loss/total_loss': 1.3199992,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.099s\n",
      "I1022 17:29:55.004694 22407418586624 model_lib_v2.py:707] Step 2000 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.49010375,\n",
      " 'Loss/box/scale': 0.57185984,\n",
      " 'Loss/object_center': 0.28574502,\n",
      " 'Loss/total_loss': 1.3477086,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:29:55.004933 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.49010375,\n",
      " 'Loss/box/scale': 0.57185984,\n",
      " 'Loss/object_center': 0.28574502,\n",
      " 'Loss/total_loss': 1.3477086,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.142s\n",
      "I1022 17:30:09.198821 22407418586624 model_lib_v2.py:707] Step 2100 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.3597403,\n",
      " 'Loss/box/scale': 0.4813783,\n",
      " 'Loss/object_center': 0.34412387,\n",
      " 'Loss/total_loss': 1.1852424,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:09.199325 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.3597403,\n",
      " 'Loss/box/scale': 0.4813783,\n",
      " 'Loss/object_center': 0.34412387,\n",
      " 'Loss/total_loss': 1.1852424,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.100s\n",
      "I1022 17:30:19.168089 22407418586624 model_lib_v2.py:707] Step 2200 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.5771544,\n",
      " 'Loss/box/scale': 0.08796654,\n",
      " 'Loss/object_center': 0.18998058,\n",
      " 'Loss/total_loss': 0.8551015,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:19.168326 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.5771544,\n",
      " 'Loss/box/scale': 0.08796654,\n",
      " 'Loss/object_center': 0.18998058,\n",
      " 'Loss/total_loss': 0.8551015,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.097s\n",
      "I1022 17:30:28.910163 22407418586624 model_lib_v2.py:707] Step 2300 per-step time 0.097s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.38043028,\n",
      " 'Loss/box/scale': 0.5020524,\n",
      " 'Loss/object_center': 0.05105132,\n",
      " 'Loss/total_loss': 0.933534,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:28.910400 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.38043028,\n",
      " 'Loss/box/scale': 0.5020524,\n",
      " 'Loss/object_center': 0.05105132,\n",
      " 'Loss/total_loss': 0.933534,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.097s\n",
      "I1022 17:30:38.657722 22407418586624 model_lib_v2.py:707] Step 2400 per-step time 0.097s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.2187038,\n",
      " 'Loss/box/scale': 0.22625957,\n",
      " 'Loss/object_center': 0.26252443,\n",
      " 'Loss/total_loss': 0.7074878,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:38.658186 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.2187038,\n",
      " 'Loss/box/scale': 0.22625957,\n",
      " 'Loss/object_center': 0.26252443,\n",
      " 'Loss/total_loss': 0.7074878,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.100s\n",
      "I1022 17:30:48.609173 22407418586624 model_lib_v2.py:707] Step 2500 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.28163135,\n",
      " 'Loss/box/scale': 0.15696298,\n",
      " 'Loss/object_center': 0.31047916,\n",
      " 'Loss/total_loss': 0.7490735,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:48.609396 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.28163135,\n",
      " 'Loss/box/scale': 0.15696298,\n",
      " 'Loss/object_center': 0.31047916,\n",
      " 'Loss/total_loss': 0.7490735,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2600 per-step time 0.100s\n",
      "I1022 17:30:58.596276 22407418586624 model_lib_v2.py:707] Step 2600 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.14184448,\n",
      " 'Loss/box/scale': 0.35447285,\n",
      " 'Loss/object_center': 0.2204048,\n",
      " 'Loss/total_loss': 0.71672213,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:30:58.596518 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.14184448,\n",
      " 'Loss/box/scale': 0.35447285,\n",
      " 'Loss/object_center': 0.2204048,\n",
      " 'Loss/total_loss': 0.71672213,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2700 per-step time 0.097s\n",
      "I1022 17:31:08.312117 22407418586624 model_lib_v2.py:707] Step 2700 per-step time 0.097s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.6159474,\n",
      " 'Loss/box/scale': 0.235038,\n",
      " 'Loss/object_center': 0.26672035,\n",
      " 'Loss/total_loss': 1.1177058,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:31:08.312597 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.6159474,\n",
      " 'Loss/box/scale': 0.235038,\n",
      " 'Loss/object_center': 0.26672035,\n",
      " 'Loss/total_loss': 1.1177058,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2800 per-step time 0.100s\n",
      "I1022 17:31:18.327169 22407418586624 model_lib_v2.py:707] Step 2800 per-step time 0.100s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.19304171,\n",
      " 'Loss/box/scale': 0.50653905,\n",
      " 'Loss/object_center': 0.29168597,\n",
      " 'Loss/total_loss': 0.9912667,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:31:18.327395 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.19304171,\n",
      " 'Loss/box/scale': 0.50653905,\n",
      " 'Loss/object_center': 0.29168597,\n",
      " 'Loss/total_loss': 0.9912667,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.099s\n",
      "I1022 17:31:28.264944 22407418586624 model_lib_v2.py:707] Step 2900 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.4874113,\n",
      " 'Loss/box/scale': 0.42496893,\n",
      " 'Loss/object_center': 0.5008794,\n",
      " 'Loss/total_loss': 1.4132596,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:31:28.265169 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.4874113,\n",
      " 'Loss/box/scale': 0.42496893,\n",
      " 'Loss/object_center': 0.5008794,\n",
      " 'Loss/total_loss': 1.4132596,\n",
      " 'learning_rate': 0.001}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.099s\n",
      "I1022 17:31:38.146536 22407418586624 model_lib_v2.py:707] Step 3000 per-step time 0.099s\n",
      "INFO:tensorflow:{'Loss/box/offset': 0.25956687,\n",
      " 'Loss/box/scale': 0.114992216,\n",
      " 'Loss/object_center': 0.31620586,\n",
      " 'Loss/total_loss': 0.6907649,\n",
      " 'learning_rate': 0.001}\n",
      "I1022 17:31:38.146771 22407418586624 model_lib_v2.py:708] {'Loss/box/offset': 0.25956687,\n",
      " 'Loss/box/scale': 0.114992216,\n",
      " 'Loss/object_center': 0.31620586,\n",
      " 'Loss/total_loss': 0.6907649,\n",
      " 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qeJGsPEgIQ1o"
   },
   "outputs": [],
   "source": [
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eb4mw_JUISAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 22:19:32.468554: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0708 22:19:38.063506 22819421218304 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0708 22:19:38.063877 22819421218304 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0708 22:19:38.063936 22819421218304 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0708 22:19:38.064001 22819421218304 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0708 22:19:38.064097 22819421218304 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-07-08 22:19:38.068546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-08 22:19:38.648954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:17:00.0, compute capability: 8.0\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/images/valid/nuts.tfrecord']\n",
      "I0708 22:19:39.516047 22819421218304 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/images/valid/nuts.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/images/valid/nuts.tfrecord']\n",
      "I0708 22:19:39.516383 22819421218304 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/images/valid/nuts.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0708 22:19:39.516447 22819421218304 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0708 22:19:39.516493 22819421218304 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0708 22:19:39.518321 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0708 22:19:39.540007 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0708 22:19:43.248471 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0708 22:19:44.512703 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/mNuts_centerNet\n",
      "I0708 22:19:46.796397 22819421218304 checkpoint_utils.py:136] Waiting for new checkpoint at Tensorflow/workspace/models/mNuts_centerNet\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/mNuts_centerNet/ckpt-4\n",
      "I0708 22:19:46.798197 22819421218304 checkpoint_utils.py:145] Found new checkpoint at Tensorflow/workspace/models/mNuts_centerNet/ckpt-4\n",
      "/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-07-08 22:20:03.415308: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-07-08 22:20:04.394565: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-08 22:20:04.394986: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-08 22:20:04.395004: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-07-08 22:20:04.395259: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-08 22:20:04.395310: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0708 22:20:04.888953 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0708 22:20:04.958847 22819421218304 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0708 22:20:05.201948 22819421218304 deprecation.py:356] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 59 images.\n",
      "I0708 22:20:08.039239 22819421218304 coco_evaluation.py:293] Performing evaluation on 59 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0708 22:20:08.040455 22819421218304 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0708 22:20:08.043006 22819421218304 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.878\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.498\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "INFO:tensorflow:Eval metrics at step 3000\n",
      "I0708 22:20:08.325868 22819421218304 model_lib_v2.py:1015] Eval metrics at step 3000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.451045\n",
      "I0708 22:20:08.359421 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.451045\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.877581\n",
      "I0708 22:20:08.360317 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.877581\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.363587\n",
      "I0708 22:20:08.361096 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.363587\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.442098\n",
      "I0708 22:20:08.361834 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.442098\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.497926\n",
      "I0708 22:20:08.362562 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.497926\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "I0708 22:20:08.363277 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.498305\n",
      "I0708 22:20:08.363976 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.498305\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.500000\n",
      "I0708 22:20:08.364709 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.500000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.527119\n",
      "I0708 22:20:08.365430 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.527119\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.487879\n",
      "I0708 22:20:08.366135 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.487879\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.571429\n",
      "I0708 22:20:08.366832 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.571429\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "I0708 22:20:08.367511 22819421218304 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "INFO:tensorflow:\t+ Loss/object_center: 1.069774\n",
      "I0708 22:20:08.368103 22819421218304 model_lib_v2.py:1018] \t+ Loss/object_center: 1.069774\n",
      "INFO:tensorflow:\t+ Loss/box/scale: 0.426992\n",
      "I0708 22:20:08.368688 22819421218304 model_lib_v2.py:1018] \t+ Loss/box/scale: 0.426992\n",
      "INFO:tensorflow:\t+ Loss/box/offset: 0.630975\n",
      "I0708 22:20:08.369270 22819421218304 model_lib_v2.py:1018] \t+ Loss/box/offset: 0.630975\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 2.127740\n",
      "I0708 22:20:08.369844 22819421218304 model_lib_v2.py:1018] \t+ Loss/total_loss: 2.127740\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/mNuts_centerNet\n",
      "I0708 22:24:46.898351 22819421218304 checkpoint_utils.py:136] Waiting for new checkpoint at Tensorflow/workspace/models/mNuts_centerNet\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
      "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 195, in checkpoints_iterator\n",
      "    checkpoint_dir, checkpoint_path, timeout=timeout)\n",
      "  File \"/home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Run evaluations on newest checkpoint. Look for \"checkpoint\" file in mNuts_centerNet folder to change which checkpoint is being evaluated\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 18:00:21.078134: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-22 18:00:27.927815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-22 18:00:28.502590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38236 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:17:00.0, compute capability: 8.0\n",
      "WARNING:tensorflow:From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W1022 18:00:29.618126 22731317589504 deprecation.py:628] From /home/andrew/miniconda3/envs/ssd/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.center_net_meta_arch.CenterNetMetaArch object at 0x14ab14015f50>, because it is not built.\n",
      "W1022 18:00:43.981008 22731317589504 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.center_net_meta_arch.CenterNetMetaArch object at 0x14ab14015f50>, because it is not built.\n",
      "W1022 18:01:52.815030 22731317589504 save.py:238] Found untraced functions such as convolutional_block_layer_call_fn, convolutional_block_layer_call_and_return_conditional_losses, residual_block_layer_call_fn, residual_block_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op while saving (showing 5 of 1302). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ./center_net_v4/saved_model/assets\n",
      "I1022 18:02:33.203035 22731317589504 builder_impl.py:780] Assets written to: ./center_net_v4/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to ./center_net_v4/pipeline.config\n",
      "I1022 18:02:35.830424 22731317589504 config_util.py:254] Writing pipeline config file to ./center_net_v4/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "export_script = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py')\n",
    "command = f\"\"\"python {export_script} \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path {files['PIPELINE_CONFIG']}\\\n",
    "    --trained_checkpoint_dir {paths[\"CHECKPOINT_PATH\"]} \\\n",
    "    --output_directory ./center_net_v4\n",
    "\"\"\"\n",
    "\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x146403073c50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from object_detection.builders import model_builder\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(os.path.join(paths['CHECKPOINT_PATH'], 'pipeline.config'))\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=True)\n",
    "\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "ckpt.restore(\"./center_net_v2/checkpoint/ckpt-0\").expect_partial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-22 18:11:01--  https://drive.google.com/uc?id=1zXfzx658zrYCAgI5zJtdHnzyDlfUgbph&export=download&confirm=t\n",
      "Resolving drive.google.com (drive.google.com)... 142.250.191.46, 2607:f8b0:4005:80f::200e\n",
      "Connecting to drive.google.com (drive.google.com)|142.250.191.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-0g-64-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bvfmoj6a7bvntvqu18mcon6biknn4kh3/1666487400000/13385269720894965035/*/1zXfzx658zrYCAgI5zJtdHnzyDlfUgbph?e=download&uuid=07eca07e-c3b6-49db-ae85-986a2115e9fb [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-10-22 18:11:02--  https://doc-0g-64-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bvfmoj6a7bvntvqu18mcon6biknn4kh3/1666487400000/13385269720894965035/*/1zXfzx658zrYCAgI5zJtdHnzyDlfUgbph?e=download&uuid=07eca07e-c3b6-49db-ae85-986a2115e9fb\n",
      "Resolving doc-0g-64-docs.googleusercontent.com (doc-0g-64-docs.googleusercontent.com)... 142.251.32.33, 2607:f8b0:4005:812::2001\n",
      "Connecting to doc-0g-64-docs.googleusercontent.com (doc-0g-64-docs.googleusercontent.com)|142.251.32.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1309115 (1.2M) [image/jpeg]\n",
      "Saving to: ‘inference_img.jpg’\n",
      "\n",
      "inference_img.jpg   100%[===================>]   1.25M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2022-10-22 18:11:02 (24.1 MB/s) - ‘inference_img.jpg’ saved [1309115/1309115]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O inference_img.jpg 'https://drive.google.com/uc?id=1zXfzx658zrYCAgI5zJtdHnzyDlfUgbph&export=download&confirm=t' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_img.jpg: JPEG image data, JFIF standard 1.01, aspect ratio, density 1x1, segment length 16, baseline, precision 8, 3024x4032, frames 3\r\n"
     ]
    }
   ],
   "source": [
    "!file inference_img.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "imgs = []\n",
    "# names = glob.glob('../../v4_testset/*')[:64] # only take a few\n",
    "names = glob.glob(\"./*.jpg\")\n",
    "for imageName in names:\n",
    "    imgs.append(cv2.imread(imageName))\n",
    "\n",
    "imgs = np.array(imgs, dtype=float)\n",
    "\n",
    "imgs = tf.convert_to_tensor(imgs, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4559822082519531\n"
     ]
    }
   ],
   "source": [
    "preprocessed_image, shapes = detection_model.preprocess(imgs)\n",
    "start = time.time()\n",
    "prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
    "dura = time.time()-start\n",
    "res = detection_model.postprocess(prediction_dict, shapes)\n",
    "print(dura/len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all = res[\"detection_scores\"].numpy()\n",
    "boxes_all = res[\"detection_boxes\"].numpy()\n",
    "for i in range(len(scores_all)):\n",
    "    scores = scores_all[i]\n",
    "    boxes = boxes_all[i]\n",
    "    idx_np = scores >= 0.25\n",
    "    content = '\\n'.join(' '.join(map(str, y)) for y in boxes[idx_np])\n",
    "    with open(f\"../../v4_at_10/centernet/{names[i].split('/')[-1].replace('.jpg', '.txt')}\", 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.3192791005291005, 0.3916170634920635, 0.006283068783068783, 0.00496031746031746], [0.4384920634920635, 0.37512400793650796, 0.006613756613756613, 0.00818452380952381], [0.39021164021164023, 0.47185019841269843, 0.010582010582010581, 0.005208333333333333], [0.414021164021164, 0.6098710317460317, 0.00992063492063492, 0.011904761904761904]], [[0.626818783068783, 0.2669890873015873, 0.00958994708994709, 0.012648809523809524], [0.5783730158730159, 0.3220486111111111, 0.01455026455026455, 0.019097222222222224], [0.3996362433862434, 0.6530257936507936, 0.015542328042328041, 0.020337301587301588], [0.44345238095238093, 0.6863839285714286, 0.016534391534391533, 0.011656746031746032], [0.5186838624338624, 0.6872519841269841, 0.014219576719576719, 0.01636904761904762], [0.49867724867724866, 0.6940724206349206, 0.016534391534391533, 0.01711309523809524], [0.4730489417989418, 0.705109126984127, 0.014219576719576719, 0.017857142857142856]], [[0.5454695767195767, 0.4164186507936508, 0.015542328042328041, 0.01636904761904762], [0.7609126984126984, 0.44543650793650796, 0.013227513227513227, 0.008432539682539682], [0.3349867724867725, 0.6615823412698413, 0.009259259259259259, 0.005704365079365079], [0.3384589947089947, 0.6677827380952381, 0.007605820105820105, 0.006696428571428571]]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Source: https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# if the bounding boxes integers, convert them to floats --\n",
    "\t# this is important since we'll be doing a bunch of divisions\n",
    "\tif boxes.dtype.kind == \"i\":\n",
    "\t\tboxes = boxes.astype(\"float\")\n",
    "\t# initialize the list of picked indexes\t\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list and add the\n",
    "\t\t# index value to the list of picked indexes\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t# for the end of the bounding box\n",
    "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\t\t# compute the width and height of the bounding box\n",
    "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
    "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
    "\t\t# compute the ratio of overlap\n",
    "\t\toverlap = (w * h) / area[idxs[:last]]\n",
    "\t\t# delete all indexes from the index list that have\n",
    "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "\treturn boxes[pick].astype(\"int\")\n",
    "\n",
    "# calculating iou https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation\n",
    "def iou(b1, b2):\n",
    "    if b1[0] < b1[0] or b1[1] < b1[1] or b2[0] < b2[0] or b2[1] < b2[1]:\n",
    "        b1, b2 = b2, b1\n",
    "\n",
    "    xA = max(b1[0], b2[0])\n",
    "    yA = max(b1[1], b2[1])\n",
    "    xB = min(b1[2], b2[2])\n",
    "    yB = min(b1[3], b2[3])\n",
    "\n",
    "    if xB < xA or yB < yA: return 0\n",
    "\n",
    "    intersect = (yA - yB) * (xA - xB)\n",
    "\n",
    "    A_Area = (b1[0]-b1[2])*(b1[1]-b1[3])\n",
    "    B_Area = (b2[0]-b2[2])*(b2[1]-b2[3])\n",
    "\n",
    "    return intersect/(A_Area+B_Area-intersect)\n",
    "\n",
    "def get_map(boxes, ground_truth):\n",
    "    thresholds = [0.05+i/20 for i in range(12)]\n",
    "    ious = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for thresh in thresholds:\n",
    "        FP = FN = TP = TN = 0 # true negatives are unused\n",
    "        for box in boxes:\n",
    "            is_fp = True # no ground truths at this location marked positive\n",
    "            for truth in ground_truth:\n",
    "                if iou(box, truth) >= thresh:\n",
    "                    if_fp = False\n",
    "                    TP += 1\n",
    "            FP += is_fp\n",
    "        \n",
    "        for truth in ground_truth:\n",
    "            is_fn = True\n",
    "            for box in boxes:\n",
    "                if iou(truth, box) >= thresh:\n",
    "                    if_fn = False\n",
    "                    break\n",
    "            FN += is_fn\n",
    "        # print(FN, FP, TP)\n",
    "        if FP+TP == 0 or FN + TP == 0: continue\n",
    "        precision.append(TP/(FP+TP))\n",
    "        recall.append(TP/(FN+TP))\n",
    "\n",
    "    recall.append(0)\n",
    "    precision.append(1)\n",
    "    vals = sorted([*zip(recall, precision)])\n",
    "    precision = [v[1] for v in vals]\n",
    "    recall = [v[0] for v in vals]\n",
    "\n",
    "    avg_prec = sum((vals[i][1]+vals[i-1][1])*.5*(vals[i][0]+vals[i-1][0]) for i in range(1, len(vals)))/len(recall)\n",
    "    return avg_prec\n",
    "\n",
    "gt_names = glob.glob('/home/andrew/mummy_nut/datasets/2.0y/test/labels/*.txt')\n",
    "gts = []\n",
    "\n",
    "for gt_file in gt_names:\n",
    "    with open(gt_file) as f:\n",
    "        gts.append([[float(x) for x in y.split(' ')[1:]] for y in f])\n",
    "        \n",
    "print(gts)\n",
    "\n",
    "scores_all = res[\"detection_scores\"].numpy()\n",
    "boxes_all = res[\"detection_boxes\"].numpy()\n",
    "\n",
    "maps = []\n",
    "all_ious = np.arange(0.1, 0.5, 0.01)\n",
    "for iou_thres in all_ious:\n",
    "    map_for_thres = 0\n",
    "    for i in range(len(scores_all)):\n",
    "        scores = scores_all[i]\n",
    "        boxes = boxes_all[i]\n",
    "        idx_np = scores >= iou_thres\n",
    "        map_for_thres+=get_map(boxes[idx_np], gts[i])\n",
    "    maps.append(map_for_thres)\n",
    "    print(map_for_thres)\n",
    "\n",
    "print(all_ious[np.array(maps).argmax()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmzrL7g469VOZFKZIPkEVc",
   "collapsed_sections": [],
   "name": "TensorFlow2 CenterNet(from tutorial).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
